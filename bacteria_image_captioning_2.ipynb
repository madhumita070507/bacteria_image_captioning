{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619326,
     "status": "ok",
     "timestamp": 1760170784337,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "v_-YjdNqSh1A",
    "outputId": "a2e11e70-ca8e-4121-cc2a-64afec466d65"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!mkdir -p /content/drive/MyDrive/Bacteria_Dataset\n",
    "\n",
    "!wget --no-check-certificate --content-disposition \\\n",
    "\"https://zenodo.org/record/10526360/files/DeepDataSet.zip?download=1\" \\\n",
    "-O /content/drive/MyDrive/Bacteria_Dataset/DeepDataSet.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8nTjhdZdUUGs"
   },
   "outputs": [],
   "source": [
    "!rm -rf \"/content/drive/MyDrive/GRAM_BACTERIA/DeepData\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erwYRJ6zXE7I"
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"/content/drive/MyDrive/GRAM_BACTERIA\"\n",
    "!unzip -q \"/content/drive/MyDrive/GRAM_BACTERIA/DeepDataSet.zip\" -d \"/content/drive/MyDrive/GRAM_BACTERIA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1763549195909,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "ad9xEbSyoWI_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1763549204225,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "QCh9DHVSrY_E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 362500,
     "status": "ok",
     "timestamp": 1760210174162,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "61k0wJ5erdAC",
    "outputId": "61b319e9-04cd-4551-fe45-1313bf206a03"
   },
   "outputs": [],
   "source": [
    "import os, random, shutil, glob\n",
    "from pathlib import Path\n",
    "\n",
    "img_root = os.path.join(base, \"images\")\n",
    "lab_root = os.path.join(base, \"labels\")\n",
    "\n",
    "# Detect if already split\n",
    "already_split = all(os.path.isdir(os.path.join(img_root, d)) for d in [\"train\",\"val\"]) and \\\n",
    "                all(os.path.isdir(os.path.join(lab_root, d)) for d in [\"train\",\"val\"])\n",
    "\n",
    "print(\"Already split?\", already_split)\n",
    "\n",
    "if not already_split:\n",
    "    # create split dirs\n",
    "    for d in [\"train\",\"val\",\"test\"]:\n",
    "        os.makedirs(os.path.join(img_root, d), exist_ok=True)\n",
    "        os.makedirs(os.path.join(lab_root, d), exist_ok=True)\n",
    "\n",
    "    # gather flat images and labels\n",
    "    imgs = sorted([p for p in glob.glob(os.path.join(img_root, \"**\",\"*.jpg\"), recursive=True)] +\n",
    "                  [p for p in glob.glob(os.path.join(img_root, \"**\",\"*.png\"), recursive=True)] +\n",
    "                  [p for p in glob.glob(os.path.join(img_root, \"**\",\"*.jpeg\"), recursive=True)])\n",
    "    # try to exclude already-in-train/val/test if they existed\n",
    "    imgs = [p for p in imgs if \"/train/\" not in p and \"/val/\" not in p and \"/test/\" not in p]\n",
    "\n",
    "    # pair with labels by name\n",
    "    pairs = []\n",
    "    for ip in imgs:\n",
    "        lp = os.path.join(lab_root, os.path.splitext(os.path.basename(ip))[0] + \".txt\")\n",
    "        if not os.path.exists(lp):\n",
    "            # also check nested labels if any\n",
    "            candidates = glob.glob(os.path.join(lab_root, \"**\", os.path.basename(lp)), recursive=True)\n",
    "            if candidates:\n",
    "                lp = candidates[0]\n",
    "        if os.path.exists(lp):\n",
    "            pairs.append((ip, lp))\n",
    "\n",
    "    print(f\"Found {len(pairs)} image/label pairs.\")\n",
    "    random.seed(42)\n",
    "    random.shuffle(pairs)\n",
    "    n = len(pairs)\n",
    "    n_train = int(0.8*n)\n",
    "    n_val   = int(0.1*n)\n",
    "    n_test  = n - n_train - n_val\n",
    "    splits = {\"train\": pairs[:n_train], \"val\": pairs[n_train:n_train+n_val], \"test\": pairs[n_train+n_val:]}\n",
    "\n",
    "    # move (copy to be safe; change to shutil.move if you want)\n",
    "    def cp(src, dst_dir):\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        shutil.copy2(src, os.path.join(dst_dir, os.path.basename(src)))\n",
    "\n",
    "    for split, items in splits.items():\n",
    "        for ip, lp in items:\n",
    "            cp(ip, os.path.join(img_root, split))\n",
    "            cp(lp, os.path.join(lab_root, split))\n",
    "\n",
    "    print({k: len(v) for k,v in splits.items()})\n",
    "else:\n",
    "    print(\"Using existing train/val/test splits.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1763549177467,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "d4fV3LvArjew"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9999,
     "status": "ok",
     "timestamp": 1760211499547,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "DhEUYpf6vSEP",
    "outputId": "6d54d745-eb5f-49c4-bacb-966931532661"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.196\n",
    "from ultralytics import YOLO\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760211095516,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "Tl18mXfzwX6h",
    "outputId": "9f4cbb7d-a81d-4669-c60e-0c346d3d5a5a"
   },
   "outputs": [],
   "source": [
    "data_yaml = \"\"\"\n",
    "path: /content/drive/MyDrive/GRAM_BACTERIA/DetectionDataSet\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: GPC\n",
    "  1: GNC\n",
    "  2: GPB\n",
    "  3: GNB\n",
    "\"\"\"\n",
    "\n",
    "with open(\"bacteria.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(\"âœ… YAML file created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 55250,
     "status": "ok",
     "timestamp": 1760211571665,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "4SfnuWj7wc5M",
    "outputId": "de665b7b-906c-4504-ffbf-118f475fc752"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y ultralytics torch torchvision torchaudio\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install ultralytics==8.0.157\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10584,
     "status": "ok",
     "timestamp": 1760211713706,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "HjyIZfcNwiyW",
    "outputId": "cd615eb5-fea6-4430-95c0-71cb1e6bfbc5"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y ultralytics\n",
    "!pip install ultralytics --no-deps --upgrade\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1760211730406,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "IZSx-htAxcfO",
    "outputId": "edf83605-db75-48b3-f443-24b050935af9"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt -O yolov8s.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1801,
     "status": "ok",
     "timestamp": 1760211743938,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "zs2jIoxnyeco",
    "outputId": "4f9ae33c-4893-4c13-f107-a9eeabf92c94"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "print(\"âœ… YOLOv8s model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1760211766341,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "ggaK2vp3yiIq",
    "outputId": "71fb4f5e-af65-47f4-8a41-1c70a18a132e"
   },
   "outputs": [],
   "source": [
    "data_yaml = \"\"\"\n",
    "path: /content/drive/MyDrive/GRAM_BACTERIA/DetectionDataSet\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: GPC\n",
    "  1: GNC\n",
    "  2: GPB\n",
    "  3: GNB\n",
    "\"\"\"\n",
    "\n",
    "with open(\"bacteria.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(\"âœ… bacteria.yaml created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXwowHDMzAri",
    "outputId": "16184fea-ba99-44d0-a0ca-5f8c88a6798d"
   },
   "outputs": [],
   "source": [
    "# ==== 0) Setup (keep this whole cell together and run once) ===================\n",
    "!pip -q uninstall -y ultralytics >/dev/null\n",
    "!pip -q install ultralytics --no-deps --upgrade >/dev/null\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, shutil, time\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---- Paths ----\n",
    "DATA_DIR   = \"/content/drive/MyDrive/GRAM_BACTERIA/DetectionDataSet\"\n",
    "BACKUP_DIR = \"/content/drive/MyDrive/GRAM_BACTERIA/yolo_training_backup\"\n",
    "os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Data YAML ----\n",
    "yaml_text = f\"\"\"\n",
    "path: {DATA_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "names:\n",
    "  0: GPC\n",
    "  1: GNC\n",
    "  2: GPB\n",
    "  3: GNB\n",
    "\"\"\"\n",
    "with open(\"bacteria.yaml\", \"w\") as f:\n",
    "  f.write(yaml_text)\n",
    "\n",
    "# ---- Get YOLOv8s weights (manual fetch avoids PyTorch 3.12 pickle issues) ----\n",
    "if not Path(\"yolov8s.pt\").exists():\n",
    "  !wget -q https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt -O yolov8s.pt\n",
    "\n",
    "# ---- Define per-epoch backup callback ----\n",
    "def _safe_backup(src_dir: str, dst_dir: str):\n",
    "  os.makedirs(dst_dir, exist_ok=True)\n",
    "  try:\n",
    "    shutil.copytree(src_dir, dst_dir, dirs_exist_ok=True)\n",
    "    print(f\"ðŸ” Backup synced to Drive at {time.strftime('%H:%M:%S')}\")\n",
    "  except Exception as e:\n",
    "    print(\"âš ï¸ Backup warning:\", e)\n",
    "\n",
    "def on_epoch_end(trainer):\n",
    "  # trainer.save_dir is this run's folder, e.g. /content/runs/detect/train\n",
    "  _safe_backup(trainer.save_dir, BACKUP_DIR)\n",
    "\n",
    "# ---- Resume logic ----\n",
    "last_ckpt = Path(BACKUP_DIR) / \"weights\" / \"last.pt\"\n",
    "if last_ckpt.exists():\n",
    "  print(f\"ðŸ”„ Resuming from: {last_ckpt}\")\n",
    "  model = YOLO(str(last_ckpt))\n",
    "  resume_flag = True\n",
    "else:\n",
    "  print(\"âœ¨ Fresh training with yolov8s.pt\")\n",
    "  model = YOLO(\"yolov8s.pt\")\n",
    "  resume_flag = False\n",
    "\n",
    "# attach callbacks (after model is created)\n",
    "\n",
    "\n",
    "\n",
    "model.add_callback(\"on_fit_epoch_end\", on_epoch_end)     # after each epoch\n",
    "model.add_callback(\"on_train_epoch_end\", on_epoch_end)   # (extra safety)\n",
    "\n",
    "# ---- Train ----\n",
    "results = model.train(\n",
    "    data=\"bacteria.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,          # if OOM, set to 8\n",
    "    workers=2,\n",
    "    optimizer=\"Adam\",\n",
    "    patience=10,\n",
    "    deterministic=True,\n",
    "    resume=resume_flag,\n",
    "    project=\"/content/runs\",\n",
    "    name=\"detect\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ---- Final backup + where to find weights ----\n",
    "run_dir = Path(results.save_dir)\n",
    "best_w = run_dir / \"weights\" / \"best.pt\"\n",
    "last_w = run_dir / \"weights\" / \"last.pt\"\n",
    "print(\"âœ… Training finished.\")\n",
    "print(\"Best :\", best_w)\n",
    "print(\"Last :\", last_w)\n",
    "\n",
    "_safe_backup(str(run_dir), BACKUP_DIR)\n",
    "print(\"ðŸ“¦ Drive backup folder:\", BACKUP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1717,
     "status": "ok",
     "timestamp": 1760273774121,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "o2amjLq2zDXg",
    "outputId": "df334fae-ce1c-446e-c63d-435aed6cf690"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "backup_folder = \"/content/drive/MyDrive/GRAM_BACTERIA/backups\"\n",
    "os.makedirs(backup_folder, exist_ok=True)\n",
    "\n",
    "source = \"/content/drive/MyDrive/GRAM_BACTERIA/runs/gnb_safe_boost_v3_p3/weights/best.pt\"\n",
    "destination = \"/content/drive/MyDrive/GRAM_BACTERIA/backups/gnb_safe_boost_v3_p3_best_backup.pt\"\n",
    "\n",
    "shutil.copy2(source, destination)\n",
    "print(\"âœ… Backup created at:\", destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24779,
     "status": "ok",
     "timestamp": 1760465731707,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "jZ84jXD0d-uB",
    "outputId": "ea6de138-b3b0-4750-dfbd-be2c4cd2c5e8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1760465740470,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "RDewmDeW7t45",
    "outputId": "fb17f81b-1779-45a0-c33c-d33de3330615"
   },
   "outputs": [],
   "source": [
    "import os, textwrap, pathlib\n",
    "\n",
    "APP_DIR = \"/content/drive/MyDrive/gram_app/app\"\n",
    "os.makedirs(f\"{APP_DIR}/models\", exist_ok=True)\n",
    "os.makedirs(f\"{APP_DIR}/static\", exist_ok=True)\n",
    "print(\"âœ… Created:\", APP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1760465746817,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "vkPuZR4I716n",
    "outputId": "420be2b9-6df7-4dcb-fd6e-d11556d170b7"
   },
   "outputs": [],
   "source": [
    "model_py = r'''\n",
    "import os, io, base64, tempfile\n",
    "from typing import Dict, Any\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration, BitsAndBytesConfig\n",
    "\n",
    "# ---------- Device ----------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------- YOLO ----------\n",
    "YOLO_WEIGHTS = \"/content/drive/MyDrive/GRAM_BACTERIA/runs/gnb_safe_boost_v3_p3/weights/best.pt\"\n",
    "assert os.path.exists(YOLO_WEIGHTS), f\"âŒ YOLO weights not found: {YOLO_WEIGHTS}\"\n",
    "yolo = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "# ---------- BLIP2 (8-bit on GPU; CPU fallback if no CUDA) ----------\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "if device == \"cuda\":\n",
    "    bnb_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=6.0)\n",
    "    vlm = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"Salesforce/blip2-flan-t5-xl\",\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"cuda\",\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "else:\n",
    "    vlm = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "\n",
    "# ---- Class maps (yours) ----\n",
    "ID2NAME = {0:\"GPC\", 1:\"GNC\", 2:\"GPB\", 3:\"GNB\"}\n",
    "NAME2LONG = {\n",
    "    \"GPC\":\"Gram-positive cocci\",\n",
    "    \"GNC\":\"Gram-negative cocci\",\n",
    "    \"GPB\":\"Gram-positive bacilli\",\n",
    "    \"GNB\":\"Gram-negative bacilli\",\n",
    "}\n",
    "\n",
    "# ============ YOUR EXACT BLIP2 PROMPT FUNCTION (UNCHANGED) ============\n",
    "@torch.no_grad()\n",
    "def generate_report(image_path, counts, percentages, avg_conf):\n",
    "    \"\"\"\n",
    "    Forced, structured microbiology paragraph with YOLO validation.\n",
    "    - Includes numeric support (percentages + mean confidence) for primary and secondary classes.\n",
    "    - Describes morphology, arrangement, and Gram-stain expectations.\n",
    "    - Adds a validation sentence: asks the model to check visible stain tone vs class expectation.\n",
    "    - Notes ambiguity if dominant/secondary percentages are close.\n",
    "    - No diagnosis; descriptive microbiology only.\n",
    "    \"\"\"\n",
    "\n",
    "    # If no detections, produce a descriptive fallback\n",
    "    if not counts:\n",
    "        prompt = (\n",
    "            \"You are a microbiology expert. Write one cohesive descriptive paragraph (5â€“6 sentences) \"\n",
    "            \"about a Gram-stained smear image where the detector reported no confident bacteria. \"\n",
    "            \"Describe general field quality, background material, and absence of characteristic coccal or bacillary forms. \"\n",
    "            \"Avoid diagnosis and recommendations. Do not fabricate counts. \"\n",
    "            \"Conclude by stating that no consistent bacterial morphology is evident.\"\n",
    "        )\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "        out = vlm.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=220,\n",
    "            num_beams=6,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.35,\n",
    "            no_repeat_ngram_size=4,\n",
    "            length_penalty=1.1,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return processor.tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    # Determine primary/secondary and dominance gap\n",
    "    ordered = sorted(percentages.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    primary_code, primary_pct = ordered[0]\n",
    "    primary_name = NAME2LONG[primary_code]\n",
    "    primary_conf = avg_conf.get(primary_code, 0)\n",
    "\n",
    "    secondary_line = \"\"\n",
    "    secondary_code = None\n",
    "    if len(ordered) > 1:\n",
    "        secondary_code, secondary_pct = ordered[1]\n",
    "        secondary_name = NAME2LONG[secondary_code]\n",
    "        secondary_conf = avg_conf.get(secondary_code, 0)\n",
    "        secondary_line = f\"{secondary_name} ({secondary_pct}% | mean conf {secondary_conf}%)\"\n",
    "    gap = primary_pct - (ordered[1][1] if len(ordered) > 1 else 0)\n",
    "    ambiguity_note = \"close\" if gap <= 10 else \"clear\"\n",
    "\n",
    "    # Build compact YOLO summary with numbers (to be referenced, not copied verbatim)\n",
    "    yolo_numbers = f\"{primary_name} ({primary_pct}% | mean conf {primary_conf}%)\"\n",
    "    if secondary_line:\n",
    "        yolo_numbers += f\"; {secondary_line}\"\n",
    "\n",
    "    # Morphology + Gram expectations (context for the model; it must rephrase)\n",
    "    gram_expect = {\n",
    "        \"GPC\": \"purple/dark crystal violet retention; spherical cells often in clusters or chains\",\n",
    "        \"GPB\": \"purple/dark crystal violet retention; elongated rods with parallel or grouped alignment\",\n",
    "        \"GNC\": \"pink/light safranin tone; rounded cells, looser clusters\",\n",
    "        \"GNB\": \"pink/light safranin tone; slender rods, scattered or parallel fields\",\n",
    "    }\n",
    "    morph_hint_primary = gram_expect.get(primary_code, \"\")\n",
    "    morph_hint_secondary = gram_expect.get(secondary_code, \"\") if secondary_code else \"\"\n",
    "\n",
    "    # Forced, structured instruction that VALIDATES YOLO vs visible stain\n",
    "    prompt = f\"\"\"\n",
    "You are a microbiology expert. Write exactly ONE paragraph (5â€“6 sentences) describing a Gram-stained smear image.\n",
    "STRICT REQUIREMENTS:\n",
    "1) Sentence 1: Reference YOLO detections as supporting evidence and explicitly name the dominant class with its percentage and mean confidence in parentheses, e.g., \"{primary_name} ({primary_pct}% | mean conf {primary_conf}%)\".\n",
    "2) Sentence 2: Describe morphology and spatial arrangement for the dominant class (e.g., rods vs cocci; parallel alignment vs clustered groups).\n",
    "3) Sentence 3: Describe Gram-stain appearance expected for the dominant class (purple/blue for Gram-positive; pink/light red for Gram-negative) and relate it to what is visible in the image.\n",
    "4) Sentence 4: If a secondary class is present, mention it with numbers in parentheses and state a visual reason it is less likely than the dominant class.\n",
    "5) Sentence 5 (and 6 if needed): Provide a validation statement that checks consistency between the expected Gram coloration for the dominant class and the visible stain tone; if the tone appears inconsistent, explicitly note potential misclassification; if consistent, say it aligns with expectations. Also mention whether the class dominance is \"{ambiguity_note}\" based on relative presence.\n",
    "ADDITIONAL RULES:\n",
    "- Include numbers ONLY inside parentheses as shown, do not list every class; keep prose natural.\n",
    "- Do NOT copy any input lines verbatim; rephrase professionally.\n",
    "- No diagnosis, no recommendations, no 'Overall impression'.\n",
    "\n",
    "YOLO numeric summary to reference (rephrase, do not copy): {yolo_numbers}\n",
    "Primary morphology/stain cues (for your reasoning, rephrase them): {morph_hint_primary}\n",
    "Secondary cues (if present, rephrase them): {morph_hint_secondary}\n",
    "\"\"\"\n",
    "\n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Strong decoding to avoid echoing and enforce full paragraph\n",
    "    out = vlm.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=260,\n",
    "        num_beams=8,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.4,\n",
    "        no_repeat_ngram_size=4,\n",
    "        length_penalty=1.15,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    text = processor.tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Safety: if it outputs too short or starts by echoing, build a minimal fallback paragraph\n",
    "    if len(text.split()) < 40 or text.lower().startswith((\"yolo\", primary_name.lower())) and \"(\" not in text:\n",
    "        secondary_piece = f\" A secondary component of {secondary_line} is present but visually less prominent.\" if secondary_line else \"\"\n",
    "        validation = (\n",
    "            \" The visible stain tone appears consistent with the dominant class expectation, supporting the detector's assignment.\"\n",
    "            if primary_code in (\"GPC\",\"GPB\") else\n",
    "            \" The visible stain tone appears consistent with a Gram-negative reaction, supporting the detector's assignment.\"\n",
    "        )\n",
    "        dominance_clause = \" Dominance appears clear in the field.\" if ambiguity_note == \"clear\" else \" Relative presence is close, so dominance should be interpreted cautiously.\"\n",
    "        text = (\n",
    "            f\"Based on YOLO AI evidence, {primary_name} ({primary_pct}% | mean conf {primary_conf}%) is the leading morphology in this smear. \"\n",
    "            f\"Cells display characteristic form and arrangement for this group, with features such as {morph_hint_primary.split(';')[1] if ';' in morph_hint_primary else morph_hint_primary}. \"\n",
    "            f\"Staining behavior matches expectations for this classification.{secondary_piece}\"\n",
    "            f\"{validation}{dominance_clause}\"\n",
    "        )\n",
    "\n",
    "    return text\n",
    "# ===================== END OF YOUR PROMPT FUNCTION =====================\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_pipeline(image: Image.Image) -> Dict[str, Any]:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmp:\n",
    "        image.save(tmp.name, format=\"JPEG\"); img_path = tmp.name\n",
    "    try:\n",
    "        r = yolo.predict(img_path, verbose=False)[0]\n",
    "        boxed_bgr = r.plot()\n",
    "        boxed_rgb = boxed_bgr[..., ::-1]\n",
    "        boxed_pil = Image.fromarray(boxed_rgb)\n",
    "        buf = io.BytesIO(); boxed_pil.save(buf, format=\"JPEG\", quality=90)\n",
    "        boxed_b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "        counts = Counter(); confidences = defaultdict(list)\n",
    "        if r.boxes is not None:\n",
    "            for b in r.boxes:\n",
    "                cls_id = int(b.cls.item()); conf = float(b.conf.item())\n",
    "                label = ID2NAME.get(cls_id, \"Unknown\")\n",
    "                counts[label] += 1; confidences[label].append(conf)\n",
    "\n",
    "        total = sum(counts.values())\n",
    "        percentages = {k: int(round((v/total)*100)) for k, v in counts.items()} if total>0 else {}\n",
    "        avg_conf = {k: int(round(float(np.mean(v))*100)) for k,v in confidences.items()} if total>0 else {}\n",
    "\n",
    "        report = generate_report(img_path, dict(counts), percentages, avg_conf)\n",
    "        return {\n",
    "            \"counts\": dict(counts),\n",
    "            \"percentages\": percentages,\n",
    "            \"avg_conf\": avg_conf,\n",
    "            \"report\": report,\n",
    "            \"boxed_image_b64\": boxed_b64,\n",
    "            \"boxed_image_mime\": \"image/jpeg\",\n",
    "        }\n",
    "    finally:\n",
    "        try: os.remove(img_path)\n",
    "        except: pass\n",
    "'''\n",
    "open(f\"{APP_DIR}/models/model.py\",\"w\").write(model_py)\n",
    "print(\"âœ… Wrote model.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1760465758514,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "bV9ha8N-73oU",
    "outputId": "09417d52-a176-45b7-bf01-219541050f8d"
   },
   "outputs": [],
   "source": [
    "main_py = r'''\n",
    "import io\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse, HTMLResponse\n",
    "from PIL import Image\n",
    "from models.model import run_pipeline\n",
    "\n",
    "app = FastAPI(title=\"Gram Bacteria Captioning\", version=\"1.0.0\")\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"], allow_credentials=True,\n",
    "    allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health(): return {\"status\":\"ok\"}\n",
    "\n",
    "INDEX_HTML = \"\"\"\n",
    "<!doctype html><meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "<title>Gram Bacteria Captioning</title>\n",
    "<style>body{font-family:system-ui,Arial,sans-serif;max-width:920px;margin:2rem auto;padding:0 1rem}\n",
    ".card{border:1px solid #ddd;border-radius:12px;padding:1rem;margin:1rem 0}\n",
    ".row{display:grid;grid-template-columns:1fr 1fr;gap:1rem}img{max-width:100%;border-radius:8px}\n",
    "textarea{width:100%;min-height:160px}.mono{font-family:ui-monospace,Menlo,Consolas,monospace}</style>\n",
    "<h1>Gram Bacteria Captioning</h1>\n",
    "<div class=\"card\">\n",
    "  <input id=\"file\" type=\"file\" accept=\"image/*\"/><button id=\"run\">Generate</button>\n",
    "  <div class=\"row\" style=\"margin-top:1rem\">\n",
    "    <div><strong>Preview</strong><img id=\"preview\" style=\"display:none\"></div>\n",
    "    <div><strong>YOLO Detections</strong><img id=\"boxed\" style=\"display:none\"></div>\n",
    "  </div>\n",
    "</div>\n",
    "<div class=\"card\"><h3>Result JSON</h3><pre id=\"json\" class=\"mono\">â€”</pre></div>\n",
    "<div class=\"card\"><h3>BLIP2 Report</h3><textarea id=\"report\" readonly></textarea></div>\n",
    "<script>\n",
    "const $=id=>document.getElementById(id);\n",
    "$(\"file\").addEventListener(\"change\",e=>{const f=e.target.files[0];if(f){$(\"preview\").src=URL.createObjectURL(f);$(\"preview\").style.display=\"block\";}});\n",
    "$(\"run\").addEventListener(\"click\",async()=>{\n",
    "  const f=$(\"file\").files[0]; if(!f){alert(\"Pick an image\");return;}\n",
    "  const form=new FormData(); form.append(\"file\", f); $(\"json\").textContent=\"Running...\";\n",
    "  try{\n",
    "    const res=await fetch(\"/predict\",{method:\"POST\",body:form});\n",
    "    const data=await res.json(); $(\"json\").textContent=JSON.stringify(data,null,2);\n",
    "    $(\"report\").value=data.report||\"\";\n",
    "    if(data.boxed_image_b64){$(\"boxed\").src=\"data:\"+(data.boxed_image_mime||\"image/jpeg\")+\";base64,\"+data.boxed_image_b64;$(\"boxed\").style.display=\"block\";}\n",
    "  }catch(err){$(\"json\").textContent=\"Error: \"+err;}\n",
    "});\n",
    "</script>\n",
    "\"\"\"\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "def index(): return HTMLResponse(INDEX_HTML)\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)) -> JSONResponse:\n",
    "    try:\n",
    "        content = await file.read()\n",
    "        image = Image.open(io.BytesIO(content)).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Invalid image: {e}\")\n",
    "    try:\n",
    "        return JSONResponse(run_pipeline(image))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Inference error: {e}\")\n",
    "'''\n",
    "open(f\"{APP_DIR}/main.py\",\"w\").write(main_py)\n",
    "print(\"âœ… Wrote main.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10301,
     "status": "ok",
     "timestamp": 1760465777960,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "eZ09hL9R76fK",
    "outputId": "1d094f9e-8a45-4b21-e1dd-f866585f96c1"
   },
   "outputs": [],
   "source": [
    "!pip -q install fastapi uvicorn pillow ultralytics transformers accelerate safetensors bitsandbytes\n",
    "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "!sudo dpkg -i cloudflared-linux-amd64.deb >/dev/null 2>&1 || true\n",
    "print(\"âœ… Deps installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZU4GklMl8LKH"
   },
   "outputs": [],
   "source": [
    "!curl -s http://localhost:8000/health\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3763,
     "status": "ok",
     "timestamp": 1760465790334,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "lsAaXAaz78si",
    "outputId": "0d1db4f0-e58e-4a86-d370-93858e1e05ef"
   },
   "outputs": [],
   "source": [
    "APP_RUN_DIR = \"/content/drive/MyDrive/gram_app/app\"\n",
    "%cd $APP_RUN_DIR\n",
    "\n",
    "# stop any previous\n",
    "!pkill -f uvicorn || echo \"no old uvicorn\"\n",
    "!pkill -f cloudflared || echo \"no old tunnel\"\n",
    "\n",
    "# start fastapi\n",
    "!nohup python3 -m uvicorn main:app --host 0.0.0.0 --port 8000 > /content/server.log 2>&1 &\n",
    "\n",
    "# start tunnel\n",
    "!nohup cloudflared tunnel --url http://localhost:8000 --no-autoupdate > /content/tunnel.log 2>&1 &\n",
    "\n",
    "# print URL and health\n",
    "!sleep 3\n",
    "!grep -o \"https://[-0-9a-z]*\\.trycloudflare.com\" /content/tunnel.log || echo \"â³ URL not ready yetâ€”run grep again in a few seconds\"\n",
    "!curl -s http://localhost:8000/health || echo \"Server not ready yet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1760465860892,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "595a0e238BUn",
    "outputId": "71d8c455-d917-40de-b686-3d5a382d6c51"
   },
   "outputs": [],
   "source": [
    "!tail -n 40 /content/server.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13458,
     "status": "ok",
     "timestamp": 1760510145324,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "4GlcR3VD8TdA",
    "outputId": "0848287a-cbc9-416d-ec36-8a5261f28935"
   },
   "outputs": [],
   "source": [
    "# Enable GPU in Runtime > Change runtime type > GPU (T4)\n",
    "!pip -q install \"transformers>=4.43\" \"peft>=0.11.1\" \"accelerate>=0.34.2\" bitsandbytes pillow ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1I_az09-97nS"
   },
   "outputs": [],
   "source": [
    "# ---- EDIT THESE PATHS ----\n",
    "# Your trained YOLO weights path:\n",
    "YOLO_WEIGHTS = \"/content/drive/MyDrive/GRAM_BACTERIA/runs/gnb_safe_boost_v3_p3/weights/best.pt\"\n",
    "\n",
    "# If you donâ€™t have a fine-tuned BLIP-2 yet, leave this empty (\"\")\n",
    "VLM_DIR = \"\"   # Optional: \"/content/drive/MyDrive/blip2_bacteria_lora\"\n",
    "\n",
    "# Folder where YOLO detection image + AI report will be saved\n",
    "SAVE_DIR = \"/content/drive/MyDrive/GRAM_BACTERIA/caption_reports/blip2_reports\"\n",
    "\n",
    "# âœ… FIX: Create the folder if it doesn't exist\n",
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767,
     "referenced_widgets": [
      "d7087c01f8a94949b9ca0785ba278ad3",
      "3a71d9e905de465f95a20c784fa315bd",
      "3494f9aadc454a1a985ecc5892845c69",
      "fc3c8551a51d4d499ccccfd2f2d6abc0",
      "96f2126491d44241ade97f13f6d79a2c",
      "ec91b557557948cdbe9d94030f0f61f7",
      "3890a208232d44518a9c6bc0f33a793c",
      "e390e673a0804172a4e7c1fb04bb2572",
      "6ad99c35f53e448289d71f664f6cf8b9",
      "de9c994f9c014f74b630b38b9926d274",
      "134eb8f8ffc34631b06dddf1e27048e6",
      "8eb692eb850f43719d10537f5168257a",
      "e686de9a5a514a35ac5b87dfb73f696b",
      "47326a879f864030b657b40792ee73db",
      "be148d8dd3e74999aaa0c44f9ac7356a",
      "fa1996cace714c1199073cf49b78f677",
      "bd175a4430f04884ba6a2d4a610a1c75",
      "dd557740f8a64ddba1b1efd332e077fc",
      "9ef9984fcbf34bd5bf0a452e20ce8be2",
      "4c541114590b4a72810969789c71fcae",
      "214d203af44f4f8b94a1c1c8d6a1ddc3",
      "25a7e09a92374f8582153be7023db33e",
      "6baf38b253f64bf89a593f8269f75c24",
      "93b76749059c4ae9855f70b9620c9b7a",
      "e74d06cd47784aceb419cfa4340fa537",
      "74579bfd8b6e4475bab2fd3c6923d34e",
      "c232e94a356c4ba3811109925ea1e07c",
      "21d653853add4b8291f239b3c4c957f9",
      "d572b9a793bd4dcfa97506b909e747b8",
      "d78be9b9a0c345c6a0d1b70bb0741a7f",
      "11e0d687b45d41a59ab193878e08dc57",
      "ad5fc11c63a14551a2505dcb0616d24c",
      "89cd3d9cf4bc45028ed77ebec6cd9fe6",
      "dec2b00e020349878453bf8527fa966c",
      "8df7f701d9e54b9b820aecab9c98f3bd",
      "d349d65941974d65a91ef10d8e070f9f",
      "0cc2d52f72244c719434bd73e9f36278",
      "58d57d27b02949b1abf8abbbb99155e9",
      "c2651bcbecc74e38bae73960abc33721",
      "0d1096fb53d64b0db52be8ebe01d25b9",
      "6d136dfeaff34c8f9782e0a36629c563",
      "455679aa5ff644c78103f2a4bf3a2ce0",
      "a96c04d3e7634a4482bf6293ba5079b4",
      "30d6f93797594cdcaa801d3448884f3b",
      "5a1404f063144517a2e0b7583e3e307d",
      "9bc670af48224d71988fd2045c25d5fd",
      "1ab43ee5079c431d90666b4c6ba1b5a1",
      "c1adaa4bdaf54602a7abe85df147755d",
      "06df5559cb6842dfb8b3f9903c36fa2b",
      "2d288385f7904e3c86f7ea917c2afac3",
      "4c372dcf272d451b8ff501e2ccce98b2",
      "85636ccd093b4424b455fea775156664",
      "ad5044ff186842568d1af30d8b60f70f",
      "c1b20c3f806c4e3c8f8156ae4821901b",
      "d91bd41f41c34523abb39e2ceba77fce",
      "9fa2ebe639294f3888fa2d5fd56e2d64",
      "119a13c70e4f4741ad28f5ee77c0b1c2",
      "65b48b656ff442f984d59944b54110e8",
      "567c8e268941473a8f38a2e5ddb31e13",
      "601581c17c094b089278b489664cebaf",
      "e14949789a2d46e696558c422ea49723",
      "47d6cc288ba749afad031bacc2243893",
      "5628e6c410c34cb3bcb9e0da91e23ffe",
      "de78e9d79d824d0a85ddb4187d1fb733",
      "7e87d2fdc425492c8ab35920325a9dab",
      "6c975b065bc64b60ae98f7e5f1b9d23d",
      "e3ae82f972734559bf331653957dbd38",
      "2f07cc6c1f0344ae869b1624d64038cb",
      "f84e0d97a90348f3abc285978f81776d",
      "f7b87b9db3144547b37a3c968a2c51c9",
      "efe10bd0aeec4bbbb932a8d2cb023f9e",
      "35b18a98e0a74b089db04b26f37644fe",
      "94ef33ab06b34961a628dcbb0a9a5827",
      "e15fc803b8804802be273f3d899c71df",
      "815a680e04484c9ba9b2814259200058",
      "ceb2787af38c4cf69ce46156614c9edb",
      "cd271f0f4f0647eaab4a6d4effe2c776",
      "5f740e2067cf43f794fdb073b0c8916e",
      "8d2f280e68fa4092878e8c109a5b152e",
      "091de1bbe01642ad8eb2a37d6e90f638",
      "e3910ab495bb47658e5641105328486b",
      "8f6a59e7710d4ad196a959473d14fce0",
      "40de331b796c41888adfd94f642ddda1",
      "c095d0c3eb7b4f7baf0da5454871b0af",
      "4f5c77bcaeab434d85d419d83bfb1c11",
      "c5b802aa4cfb4743bffd565cbd31cf53",
      "9f91ea9048484d059b60b9f0580408be",
      "22bd43ff0cb94c0eb714c6a5927e9612",
      "ceb955c4c7584ec49024e134f9338371",
      "dc4251b2d6444a9d936ce1ecff6c52b1",
      "31a62e8e069745d2b6ee94e624ca07e4",
      "1e8d78f6f78f42ca959ecc8e139c62cb",
      "585b1686918d48968e0dae5e9665aa10",
      "208adb3991fc4ca6a4149a176c3269ec",
      "08a14fb1b485429a9bca5d9088a3a260",
      "6416914c38774faaac39e3b755867ee0",
      "aef77b29e9e24962b91bb7b36b7ac8b2",
      "5a6c3d207d354865a6e926750850b2b0",
      "7828539d519444059f4fe21b21653ba7",
      "2fce08710d5a431dbc667bb17a615c3a",
      "c3e8b44d01da46c8bcfb1d70dbf5bc49",
      "40c4ee1642144743876b07fdab44bff7",
      "ea1e5120e66a48a4aa486725cff4a273",
      "99093e17eb3047aa8548f5735797a5a1",
      "0ad2d6d5ccd341ab85cc47bb9cc91658",
      "c56290e40ed347fca1fb9fff03736340",
      "767c3ce257a742658ef18306197e3896",
      "37df37f695ad4720a625bec1e8643faf",
      "080e15f5d83146cfaa52ab3061a600a7",
      "414c8f54d3e24fac84b13cab950987cc",
      "6261fc5fe20f41debb67351878ca4ce4",
      "d251ca92189e45d492680397d3560124",
      "beee0e6a64e348239d36cf041016f639",
      "f5c075b18ed54c84ae4e9b2b1c75eed5",
      "16f2c4f7074540f7b1adc38110ee83c9",
      "6072568c10414c549dd0ca290d82326f",
      "999a5fb4ec194ee889856f745543f43d",
      "bd9a02fb64f047a3b7f6b5f40d3a8599",
      "4dd3a143a9c447da888704845b1cad18",
      "ee1421a04a4a44dd87de6f27f5e13771",
      "c7000b62c1fe4ee3b93b9e20add551de",
      "0ea196cdd6514462a89a582abe7a9ddc",
      "0edb34ae34dc4ddd86367c6c5c4a9332",
      "1103677dd800469d92dc1ebfdb41e26c",
      "a50ada61a9c5424dadc0b34c92d269fa",
      "fdc3ef368adc456ba9851c45cf9493c1",
      "e1aa5a11785341fe95913069be95b3de",
      "a8ecf78b1f064545a8feeff2e9bb2348",
      "0abb056f86cb427cb12e83f43d2695c9",
      "72c17a064e014c3999b8ce6ba457758c",
      "910355e5292340f0b2985280835bc3d7",
      "5513d267d3004b11a2120fe056bcd1a1",
      "a8546e7ab6d94c1f85f31977f37caf26",
      "cf5d5095c12d4beeadebbaf5d44990bb",
      "bcff8f96bcc04b348fadf17f66cb4742",
      "1638b618a99b45998fe0c313163e8370",
      "63447b9d451447009ceb5e540c64ed1e",
      "ad85338931844625b6e052f80b0d1a68",
      "109cbadef1aa4c988ec0126502992079",
      "a0d8340450dc4b5d819d1cbea4b4edc5",
      "07b2e53f4d3a4682b06e2071fb62e194",
      "054f19fff7fb49f79740750dfbcf45d5",
      "46b599c129b5478da7c89fb3890882a4",
      "ec73bc90703740b9a830fa86d00f2436",
      "69331edd5c2c4e9da3b63e98209af883",
      "bda5b51ac033457bac5abc8260f91c0e",
      "d1ee5cac62bc496ab526679ae96086b2",
      "cf833ae29ca1417c99f4976ee5013503",
      "038ba7003e4c41eb954f379a0a236900",
      "96beae15765a4454b1bdc58e807e1d08",
      "d9b60b5b3a3c4c8b8392c5088c3689d8",
      "5b8b36b0a4be4535a909eca320a49f8d",
      "782b25fc2e75409a8e7bf804140d2739",
      "b607d53359574c739924a7111ce9c688"
     ]
    },
    "executionInfo": {
     "elapsed": 964735,
     "status": "ok",
     "timestamp": 1760511113983,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "a59N2eNz9945",
    "outputId": "607ad1d7-afdf-4a1a-ebd4-4841f96fa359"
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from ultralytics import YOLO\n",
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Load YOLO ---\n",
    "assert os.path.isfile(YOLO_WEIGHTS), f\"âŒ YOLO weights not found: {YOLO_WEIGHTS}\"\n",
    "yolo = YOLO(YOLO_WEIGHTS)\n",
    "print(\"âœ… YOLO model loaded.\")\n",
    "\n",
    "# --- Load BLIP-2 ---\n",
    "if VLM_DIR and os.path.isdir(VLM_DIR):\n",
    "    print(f\"âœ… Loading fine-tuned BLIP-2 from: {VLM_DIR}\")\n",
    "    processor = AutoProcessor.from_pretrained(VLM_DIR)\n",
    "    vlm = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        VLM_DIR, device_map=\"auto\", load_in_8bit=True\n",
    "    )\n",
    "else:\n",
    "    print(\"âœ… Loading base BLIP-2 model: Salesforce/blip2-flan-t5-xl\")\n",
    "    processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "    vlm = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"Salesforce/blip2-flan-t5-xl\", device_map=\"auto\", load_in_8bit=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMB9PZwnkoxW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 6995,
     "status": "ok",
     "timestamp": 1760512743758,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "40nNjdbV-AQd",
    "outputId": "88cafd68-7ab7-4d0a-c744-955d2eeaf6a3"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Choose your Gram-stained microscopy image\n",
    "image_path = next(iter(uploaded.keys()))\n",
    "print(\"âœ… Image loaded:\", image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_UEtj3I-wcx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1760512748596,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "u0LxGViH-1tm",
    "outputId": "27acb98a-4322-4ff7-aecb-31e361c08864"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ID2NAME = {0:\"GPC\", 1:\"GNC\", 2:\"GPB\", 3:\"GNB\"}\n",
    "NAME2LONG = {\n",
    "    \"GPC\":\"Gram-positive cocci\",\n",
    "    \"GNC\":\"Gram-negative cocci\",\n",
    "    \"GPB\":\"Gram-positive bacilli\",\n",
    "    \"GNB\":\"Gram-negative bacilli\",\n",
    "}\n",
    "\n",
    "result = yolo.predict(image_path, verbose=False)\n",
    "r = result[0]\n",
    "\n",
    "boxed_image = r.plot()\n",
    "boxed_path = os.path.join(SAVE_DIR, f\"{Path(image_path).stem}_yolo.jpg\")\n",
    "Image.fromarray(boxed_image[..., ::-1]).save(boxed_path)\n",
    "\n",
    "counts = Counter()\n",
    "confidences = defaultdict(list)\n",
    "\n",
    "if r.boxes is not None:\n",
    "    for box in r.boxes:\n",
    "        cls_id = int(box.cls.item())\n",
    "        conf = float(box.conf.item())\n",
    "        label = ID2NAME.get(cls_id, \"Unknown\")\n",
    "        counts[label] += 1\n",
    "        confidences[label].append(conf)\n",
    "\n",
    "total = sum(counts.values())\n",
    "percentages = {k: int(round((v/total)*100)) for k, v in counts.items()} if total > 0 else {}\n",
    "avg_conf = {k: int(round(np.mean(v)*100)) for k, v in confidences.items()}\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(Image.open(boxed_path))\n",
    "plt.axis('off')\n",
    "plt.title(\"YOLO Detection Evidence\")\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… YOLO Detection Summary\")\n",
    "print(\"Counts:\", dict(counts))\n",
    "print(\"Percentages:\", percentages)\n",
    "print(\"Avg Confidence (%):\", avg_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19844,
     "status": "ok",
     "timestamp": 1760512776835,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "e8V_gmOM-3Pd",
    "outputId": "0e22ad0a-af41-425d-e83a-4a18d1111e89"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_report(image_path, counts, percentages, avg_conf):\n",
    "    \"\"\"\n",
    "    Forced, structured microbiology paragraph with YOLO validation.\n",
    "    - Includes numeric support (percentages + mean confidence) for primary and secondary classes.\n",
    "    - Describes morphology, arrangement, and Gram-stain expectations.\n",
    "    - Adds a validation sentence: asks the model to check visible stain tone vs class expectation.\n",
    "    - Notes ambiguity if dominant/secondary percentages are close.\n",
    "    - No diagnosis; descriptive microbiology only.\n",
    "    \"\"\"\n",
    "\n",
    "    # Class name maps (already defined earlier in your notebook)\n",
    "    # NAME2LONG = {\"GPC\":\"Gram-positive cocci\",\"GNC\":\"Gram-negative cocci\",\"GPB\":\"Gram-positive bacilli\",\"GNB\":\"Gram-negative bacilli\"}\n",
    "\n",
    "    # If no detections, produce a descriptive fallback\n",
    "    if not counts:\n",
    "        prompt = (\n",
    "            \"You are a microbiology expert. Write one cohesive descriptive paragraph (5â€“6 sentences) \"\n",
    "            \"about a Gram-stained smear image where the detector reported no confident bacteria. \"\n",
    "            \"Describe general field quality, background material, and absence of characteristic coccal or bacillary forms. \"\n",
    "            \"Avoid diagnosis and recommendations. Do not fabricate counts. \"\n",
    "            \"Conclude by stating that no consistent bacterial morphology is evident.\"\n",
    "        )\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "        out = vlm.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=220,\n",
    "            num_beams=6,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.35,\n",
    "            no_repeat_ngram_size=4,\n",
    "            length_penalty=1.1,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return processor.tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    # Determine primary/secondary and dominance gap\n",
    "    ordered = sorted(percentages.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    primary_code, primary_pct = ordered[0]\n",
    "    primary_name = NAME2LONG[primary_code]\n",
    "    primary_conf = avg_conf.get(primary_code, 0)\n",
    "\n",
    "    secondary_line = \"\"\n",
    "    secondary_code = None\n",
    "    if len(ordered) > 1:\n",
    "        secondary_code, secondary_pct = ordered[1]\n",
    "        secondary_name = NAME2LONG[secondary_code]\n",
    "        secondary_conf = avg_conf.get(secondary_code, 0)\n",
    "        secondary_line = f\"{secondary_name} ({secondary_pct}% | mean conf {secondary_conf}%)\"\n",
    "    gap = primary_pct - (ordered[1][1] if len(ordered) > 1 else 0)\n",
    "    ambiguity_note = \"close\" if gap <= 10 else \"clear\"\n",
    "\n",
    "    # Build compact YOLO summary with numbers (to be referenced, not copied verbatim)\n",
    "    yolo_numbers = f\"{primary_name} ({primary_pct}% | mean conf {primary_conf}%)\"\n",
    "    if secondary_line:\n",
    "        yolo_numbers += f\"; {secondary_line}\"\n",
    "\n",
    "    # Morphology + Gram expectations (context for the model; it must rephrase)\n",
    "    gram_expect = {\n",
    "        \"GPC\": \"purple/dark crystal violet retention; spherical cells often in clusters or chains\",\n",
    "        \"GPB\": \"purple/dark crystal violet retention; elongated rods with parallel or grouped alignment\",\n",
    "        \"GNC\": \"pink/light safranin tone; rounded cells, looser clusters\",\n",
    "        \"GNB\": \"pink/light safranin tone; slender rods, scattered or parallel fields\",\n",
    "    }\n",
    "    morph_hint_primary = gram_expect.get(primary_code, \"\")\n",
    "    morph_hint_secondary = gram_expect.get(secondary_code, \"\") if secondary_code else \"\"\n",
    "\n",
    "    # Forced, structured instruction that VALIDATES YOLO vs visible stain\n",
    "    prompt = f\"\"\"\n",
    "You are a microbiology expert. Write exactly ONE paragraph (5â€“6 sentences) describing a Gram-stained smear image.\n",
    "STRICT REQUIREMENTS:\n",
    "1) Sentence 1: Reference YOLO detections as supporting evidence and explicitly name the dominant class with its percentage and mean confidence in parentheses, e.g., \"{primary_name} ({primary_pct}% | mean conf {primary_conf}%)\".\n",
    "2) Sentence 2: Describe morphology and spatial arrangement for the dominant class (e.g., rods vs cocci; parallel alignment vs clustered groups).\n",
    "3) Sentence 3: Describe Gram-stain appearance expected for the dominant class (purple/blue for Gram-positive; pink/light red for Gram-negative) and relate it to what is visible in the image.\n",
    "4) Sentence 4: If a secondary class is present, mention it with numbers in parentheses and state a visual reason it is less likely than the dominant class.\n",
    "5) Sentence 5 (and 6 if needed): Provide a validation statement that checks consistency between the expected Gram coloration for the dominant class and the visible stain tone; if the tone appears inconsistent, explicitly note potential misclassification; if consistent, say it aligns with expectations. Also mention whether the class dominance is \"{ambiguity_note}\" based on relative presence.\n",
    "ADDITIONAL RULES:\n",
    "- Include numbers ONLY inside parentheses as shown, do not list every class; keep prose natural.\n",
    "- Do NOT copy any input lines verbatim; rephrase professionally.\n",
    "- No diagnosis, no recommendations, no 'Overall impression'.\n",
    "\n",
    "YOLO numeric summary to reference (rephrase, do not copy): {yolo_numbers}\n",
    "Primary morphology/stain cues (for your reasoning, rephrase them): {morph_hint_primary}\n",
    "Secondary cues (if present, rephrase them): {morph_hint_secondary}\n",
    "\"\"\"\n",
    "\n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Strong decoding to avoid echoing and enforce full paragraph\n",
    "    out = vlm.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=260,\n",
    "        num_beams=8,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.4,\n",
    "        no_repeat_ngram_size=4,\n",
    "        length_penalty=1.15,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    text = processor.tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Safety: if it outputs too short or starts by echoing, build a minimal fallback paragraph\n",
    "    if len(text.split()) < 40 or text.lower().startswith((\"yolo\", primary_name.lower())) and \"(\" not in text:\n",
    "        secondary_piece = f\" A secondary component of {secondary_line} is present but visually less prominent.\" if secondary_line else \"\"\n",
    "        validation = (\n",
    "            \" The visible stain tone appears consistent with the dominant class expectation, supporting the detector's assignment.\"\n",
    "            if primary_code in (\"GPC\",\"GPB\") else\n",
    "            \" The visible stain tone appears consistent with a Gram-negative reaction, supporting the detector's assignment.\"\n",
    "        )\n",
    "        dominance_clause = \" Dominance appears clear in the field.\" if ambiguity_note == \"clear\" else \" Relative presence is close, so dominance should be interpreted cautiously.\"\n",
    "        text = (\n",
    "            f\"Based on YOLO AI evidence, {primary_name} ({primary_pct}% | mean conf {primary_conf}%) is the leading morphology in this smear. \"\n",
    "            f\"Cells display characteristic form and arrangement for this group, with features such as {morph_hint_primary.split(';')[1] if ';' in morph_hint_primary else morph_hint_primary}. \"\n",
    "            f\"Staining behavior matches expectations for this classification.{secondary_piece}\"\n",
    "            f\"{validation}{dominance_clause}\"\n",
    "        )\n",
    "\n",
    "    return text\n",
    "\n",
    "# Generate and print paragraph\n",
    "report = generate_report(image_path, counts, percentages, avg_conf)\n",
    "print(\"\\n===== GENERATED REPORT =====\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760512544668,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "ER2pV1CLiVOJ",
    "outputId": "a3761ebd-39fd-488b-8659-c3125f3be1ae"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "# âœ… Define expected classes and traits\n",
    "CLASS_MAP = {\n",
    "    \"GPC\": {\"gram\": \"positive\", \"shape\": \"cocci\"},\n",
    "    \"GNC\": {\"gram\": \"negative\", \"shape\": \"cocci\"},\n",
    "    \"GPB\": {\"gram\": \"positive\", \"shape\": \"bacilli\"},\n",
    "    \"GNB\": {\"gram\": \"negative\", \"shape\": \"bacilli\"},\n",
    "}\n",
    "\n",
    "# âœ… Expected structure rules\n",
    "def evaluate_blip_caption(caption_text):\n",
    "    score = 0\n",
    "    reasons = []\n",
    "\n",
    "    caption = caption_text.lower()\n",
    "\n",
    "    # --- 1ï¸âƒ£ Detect class mention (GPC, GPB, GNC, GNB)\n",
    "    detected_class = None\n",
    "    for key, details in CLASS_MAP.items():\n",
    "        if key.lower() in caption or details[\"shape\"] in caption:\n",
    "            detected_class = key\n",
    "            score += 20\n",
    "            reasons.append(f\"âœ… Detected class mention ({key})\")\n",
    "            break\n",
    "    if not detected_class:\n",
    "        reasons.append(\"âŒ No class mention detected\")\n",
    "\n",
    "    # --- 2ï¸âƒ£ Check Gram consistency\n",
    "    if detected_class:\n",
    "        gram_expected = CLASS_MAP[detected_class][\"gram\"]\n",
    "        if gram_expected in caption:\n",
    "            score += 20\n",
    "            reasons.append(f\"âœ… Gram-stain tone matches expected ({gram_expected})\")\n",
    "        else:\n",
    "            reasons.append(f\"âš ï¸ Gram tone missing or inconsistent ({gram_expected} expected)\")\n",
    "\n",
    "    # --- 3ï¸âƒ£ Morphology correctness\n",
    "    if detected_class:\n",
    "        shape_expected = CLASS_MAP[detected_class][\"shape\"]\n",
    "        if shape_expected in caption:\n",
    "            score += 15\n",
    "            reasons.append(f\"âœ… Morphology consistent ({shape_expected})\")\n",
    "        else:\n",
    "            reasons.append(f\"âš ï¸ Morphology not mentioned ({shape_expected} expected)\")\n",
    "\n",
    "    # --- 4ï¸âƒ£ YOLO numeric evidence\n",
    "    if re.search(r'\\d+%.*conf', caption):\n",
    "        score += 15\n",
    "        reasons.append(\"âœ… YOLO numeric evidence found (percent/confidence)\")\n",
    "    else:\n",
    "        reasons.append(\"âš ï¸ No numeric reference to YOLO evidence\")\n",
    "\n",
    "    # --- 5ï¸âƒ£ Sentence structure (5â€“6 sentences)\n",
    "    sentence_count = len(re.split(r'[.!?]', caption))\n",
    "    if 4 <= sentence_count <= 7:\n",
    "        score += 15\n",
    "        reasons.append(f\"âœ… Proper structure ({sentence_count} sentences)\")\n",
    "    else:\n",
    "        reasons.append(f\"âš ï¸ Sentence count off ({sentence_count})\")\n",
    "\n",
    "    # --- 6ï¸âƒ£ Safety check: No diagnosis or medical claims\n",
    "    bad_phrases = [\"infection\", \"disease\", \"treatment\", \"patient\", \"therapy\", \"antibiotic\"]\n",
    "    if not any(bp in caption for bp in bad_phrases):\n",
    "        score += 10\n",
    "        reasons.append(\"âœ… No medical claims found\")\n",
    "    else:\n",
    "        reasons.append(\"âŒ Contains diagnostic/medical phrasing\")\n",
    "\n",
    "    # --- 7ï¸âƒ£ Grammar & readability\n",
    "    tb = TextBlob(caption_text)\n",
    "    if tb.sentiment.polarity > -0.5:  # crude readability check\n",
    "        score += 5\n",
    "        reasons.append(\"âœ… Language and grammar acceptable\")\n",
    "    else:\n",
    "        reasons.append(\"âš ï¸ Language clarity issues\")\n",
    "\n",
    "    final = min(score, 100)\n",
    "    print(\"\\n===== ðŸ§ª BLIP CAPTION EVALUATION =====\")\n",
    "    for r in reasons:\n",
    "        print(r)\n",
    "    print(f\"\\nðŸ§© Final Caption Quality Score: {final}/100\")\n",
    "    return final, reasons\n",
    "\n",
    "# âœ… Run the evaluation\n",
    "caption_text = \"\"\"\n",
    "\n",
    "===== GENERATED REPORT =====\n",
    "\n",
    "Based on YOLO AI evidence, Gram-positive cocci (75% | mean conf 58%) is the leading morphology in this smear. Cells display characteristic form and arrangement for this group, with features such as  spherical cells often in clusters or chains. Staining behavior matches expectations for this classification. A secondary component of Gram-positive bacilli (25% | mean conf 62%) is present but visually less prominent. The visible stain tone appears consistent with the dominant class expectation, supporting the detector's assignment. Dominance appears clear in the field.\n",
    "\n",
    "\"\"\"\n",
    "evaluate_blip_caption(caption_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEPMSzWnyBw8"
   },
   "outputs": [],
   "source": [
    "# --- Helper: extract CLIP-safe short text from long BLIP captions ---\n",
    "def get_clip_safe_text(caption: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract a short version of the caption safe for CLIP (max length 77 tokens).\n",
    "    Uses Sentence 1 from your structured microbiology report.\n",
    "    \"\"\"\n",
    "    # Take first sentence\n",
    "    first_sentence = caption.strip().split(\".\")[0]\n",
    "    if not first_sentence or len(first_sentence) < 10:\n",
    "        return \"Microscopic Gram-stained bacteria visible.\"\n",
    "    return first_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6762,
     "status": "ok",
     "timestamp": 1760513616874,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "V7moJ59q-7HQ",
    "outputId": "571ed9f6-5610-498f-a1b5-5a6acef340e1"
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SINGLE-IMAGE CAPTION EVALUATION (Rule-based + CLIP)\n",
    "# Drop this AFTER you have: image_path, counts, percentages, avg_conf, and report (your BLIP2 output)\n",
    "# =========================\n",
    "\n",
    "import re, math, os, torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Tuple, Optional\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Load CLIP once (small & fast) ---\n",
    "_clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "_clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# --- Helpers: map your 4 classes to Gram & morphology ---\n",
    "GRAM_MAP = {\n",
    "    \"GPC\": (\"positive\", \"cocci\"),\n",
    "    \"GPB\": (\"positive\", \"bacilli\"),\n",
    "    \"GNC\": (\"negative\", \"cocci\"),\n",
    "    \"GNB\": (\"negative\", \"bacilli\"),\n",
    "}\n",
    "\n",
    "POS_WORDS  = {\"gram-positive\", \"gram positive\", \"positive\"}\n",
    "NEG_WORDS  = {\"gram-negative\", \"gram negative\", \"negative\"}\n",
    "COCCI_WORDS = {\"cocci\", \"coccus\", \"clusters\", \"chain\", \"chains\"}\n",
    "ROD_WORDS   = {\"bacilli\", \"bacillus\", \"rod\", \"rods\", \"elongated\", \"slender rods\"}\n",
    "PURPLE_WORDS = {\"purple\", \"violet\", \"blue\", \"crystal violet\"}\n",
    "PINK_WORDS   = {\"pink\", \"red\", \"light red\", \"safranin\"}\n",
    "\n",
    "DIAGNOSE_WORDS = {\"treat\", \"therapy\", \"antibiotic\", \"patient\", \"prescribe\", \"diagnosis\", \"diagnose\", \"recommendation\"}\n",
    "\n",
    "P_NUM = re.compile(r\"\\(\\s*\\d+%\")              # any percent inside parentheses\n",
    "P_MEAN = re.compile(r\"mean conf\\s*\\d+%\")      # \"mean conf 87%\" style\n",
    "P_SECONDARY = re.compile(r\"secondary\", re.I)  # looks for mention of secondary\n",
    "\n",
    "@dataclass\n",
    "class RuleChecks:\n",
    "    has_pos_or_neg: bool\n",
    "    mentions_cocci_or_bacilli: bool\n",
    "    mentions_stain_color: bool\n",
    "    has_numeric_evidence: bool\n",
    "    mentions_validation_consistency: bool\n",
    "    sentence_count_ok: bool\n",
    "    avoids_diagnosis: bool\n",
    "    yolo_gram_match: bool\n",
    "    yolo_morph_match: bool\n",
    "\n",
    "@dataclass\n",
    "class EvalScores:\n",
    "    rule_score: float\n",
    "    clip_score: float\n",
    "    final_score: float\n",
    "\n",
    "def _clean(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", text.lower()).strip()\n",
    "\n",
    "def infer_caption_gram_and_morph(text: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Infer (gram, morph) from caption text.\"\"\"\n",
    "    t = _clean(text)\n",
    "    gram = None\n",
    "    morph = None\n",
    "\n",
    "    if any(w in t for w in POS_WORDS):\n",
    "        gram = \"positive\"\n",
    "    elif any(w in t for w in NEG_WORDS):\n",
    "        gram = \"negative\"\n",
    "\n",
    "    if any(w in t for w in COCCI_WORDS):\n",
    "        morph = \"cocci\"\n",
    "    elif any(w in t for w in ROD_WORDS):\n",
    "        morph = \"bacilli\"\n",
    "\n",
    "    return gram, morph\n",
    "\n",
    "def infer_caption_stain(text: str) -> Optional[str]:\n",
    "    t = _clean(text)\n",
    "    if any(w in t for w in PURPLE_WORDS): return \"purple\"\n",
    "    if any(w in t for w in PINK_WORDS):   return \"pink\"\n",
    "    return None\n",
    "\n",
    "def yolo_majority(percentages: Dict[str, int]) -> Optional[str]:\n",
    "    return max(percentages, key=percentages.get) if percentages else None\n",
    "\n",
    "@torch.no_grad()\n",
    "def clip_image_text_similarity(image_path: str, text: str) -> float:\n",
    "    \"\"\"Return CLIP cosine similarity in [0,1].\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = _clip_proc(text=[text], images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = _clip_model(**inputs)\n",
    "    img_emb = outputs.image_embeds / outputs.image_embeds.norm(dim=-1, keepdim=True)\n",
    "    txt_emb = outputs.text_embeds  / outputs.text_embeds.norm(dim=-1, keepdim=True)\n",
    "    sim = (img_emb @ txt_emb.T).squeeze().item()  # cosine in [-1,1]\n",
    "    sim01 = 0.5 * (sim + 1.0)                     # map to [0,1]\n",
    "    return float(sim01)\n",
    "\n",
    "def build_rule_checks(\n",
    "    caption: str,\n",
    "    percentages: Dict[str, int],\n",
    ") -> RuleChecks:\n",
    "    cap = _clean(caption)\n",
    "    sent_count = max(1, caption.count(\".\") + caption.count(\"!\") + caption.count(\"?\"))\n",
    "\n",
    "    cap_gram, cap_morph = infer_caption_gram_and_morph(cap)\n",
    "    stain = infer_caption_stain(cap)\n",
    "\n",
    "    has_posneg = (cap_gram is not None)\n",
    "    mentions_morph = (cap_morph is not None)\n",
    "    mentions_color = (stain is not None)\n",
    "\n",
    "    num_evidence = bool(P_NUM.search(caption)) and bool(P_MEAN.search(caption))\n",
    "    mentions_validation = (\"consistent\" in cap) or (\"inconsistent\" in cap) or (\"misclassification\" in cap)\n",
    "    sentence_ok = (5 <= sent_count <= 6)\n",
    "    no_diag = not any(w in cap for w in DIAGNOSE_WORDS)\n",
    "\n",
    "    top = yolo_majority(percentages)\n",
    "    if top in GRAM_MAP:\n",
    "        y_gram, y_morph = GRAM_MAP[top]\n",
    "        gram_match  = (cap_gram == y_gram) if cap_gram else False\n",
    "        morph_match = (cap_morph == y_morph) if cap_morph else False\n",
    "    else:\n",
    "        gram_match = morph_match = False\n",
    "\n",
    "    return RuleChecks(\n",
    "        has_pos_or_neg=has_posneg,\n",
    "        mentions_cocci_or_bacilli=mentions_morph,\n",
    "        mentions_stain_color=mentions_color,\n",
    "        has_numeric_evidence=num_evidence,\n",
    "        mentions_validation_consistency=mentions_validation,\n",
    "        sentence_count_ok=sentence_ok,\n",
    "        avoids_diagnosis=no_diag,\n",
    "        yolo_gram_match=gram_match,\n",
    "        yolo_morph_match=morph_match,\n",
    "    )\n",
    "\n",
    "def score_rules(rc: RuleChecks) -> float:\n",
    "    \"\"\"\n",
    "    Weighted rule score (0â€“100).\n",
    "    Emphasis on YOLO consistency and numeric support, as per your prompt spec.\n",
    "    \"\"\"\n",
    "    pts = 0.0\n",
    "    # Consistency (50 total)\n",
    "    pts += 25 if rc.yolo_gram_match else 0\n",
    "    pts += 15 if rc.yolo_morph_match else 0\n",
    "    pts += 10 if rc.mentions_validation_consistency else 0\n",
    "\n",
    "    # Evidence & content (35 total)\n",
    "    pts += 15 if rc.has_numeric_evidence else 0\n",
    "    pts += 10 if rc.has_pos_or_neg else 0\n",
    "    pts += 10 if rc.mentions_cocci_or_bacilli else 0\n",
    "\n",
    "    # Style & safety (15 total)\n",
    "    pts += 10 if rc.sentence_count_ok else 0\n",
    "    pts += 5  if rc.avoids_diagnosis else 0\n",
    "\n",
    "    return float(pts)\n",
    "\n",
    "def evaluate_caption(\n",
    "    image_path: str,\n",
    "    caption_text: str,\n",
    "    percentages: Dict[str, int],\n",
    "    return_dict: bool = False\n",
    ") -> Tuple[RuleChecks, EvalScores]:\n",
    "    \"\"\"Main entry: runs rule checks + CLIP and returns both plus combined score.\"\"\"\n",
    "    # 1) Rule checks\n",
    "    rc = build_rule_checks(caption_text, percentages)\n",
    "    rscore = score_rules(rc)  # 0â€“100\n",
    "\n",
    "    # 2) CLIP similarity in 0â€“1 â†’ scale to 0â€“100\n",
    "    clip_text= get_clip_safe_text(caption_text)\n",
    "    cscore = clip_image_text_similarity(image_path, clip_text) * 100.0\n",
    "\n",
    "    # 3) Final blend: 60% rules + 40% CLIP\n",
    "    final = 0.60 * rscore + 0.40 * cscore\n",
    "\n",
    "    scores = EvalScores(rule_score=rscore, clip_score=cscore, final_score=final)\n",
    "    if return_dict:\n",
    "        return asdict(rc), asdict(scores)\n",
    "    return rc, scores\n",
    "\n",
    "# =========================\n",
    "# ðŸ”§ HOW TO USE (single image you already processed)\n",
    "# Requires:\n",
    "#   - image_path  (your uploaded image)\n",
    "#   - percentages (from your YOLO summary dict)\n",
    "#   - report      (the exact text returned by your generate_report; we DO NOT change your prompt)\n",
    "# =========================\n",
    "\n",
    "rc, scores = evaluate_caption(image_path, report, percentages)\n",
    "\n",
    "top = yolo_majority(percentages)\n",
    "print(\"\\n===== CAPTION EVALUATION (Single Image) =====\")\n",
    "print(f\"YOLO Top Class: {top}  -> gram/morph = {GRAM_MAP.get(top, ('?','?'))}\")\n",
    "print(f\"Rule score: {scores.rule_score:.1f}/100\")\n",
    "print(f\"CLIP image-text similarity: {scores.clip_score:.1f}/100\")\n",
    "print(f\"FINAL score (60% rules + 40% CLIP): {scores.final_score:.1f}/100\\n\")\n",
    "\n",
    "print(\"â€” Rule checks â€”\")\n",
    "print(f\"âœ“ Mentions Gram (pos/neg):        {rc.has_pos_or_neg}\")\n",
    "print(f\"âœ“ Mentions morphology (cocci/rods): {rc.mentions_cocci_or_bacilli}\")\n",
    "print(f\"âœ“ Mentions stain color:            {rc.mentions_stain_color}\")\n",
    "print(f\"âœ“ Numeric evidence present:        {rc.has_numeric_evidence}\")\n",
    "print(f\"âœ“ Validation consistency sentence: {rc.mentions_validation_consistency}\")\n",
    "print(f\"âœ“ 5â€“6 sentences:                   {rc.sentence_count_ok}\")\n",
    "print(f\"âœ“ Avoids diagnosis:                {rc.avoids_diagnosis}\")\n",
    "print(f\"âœ“ YOLO Gram match:                 {rc.yolo_gram_match}\")\n",
    "print(f\"âœ“ YOLO Morph match:                {rc.yolo_morph_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMLe9h3RDfUZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--UJ6EYwGSSS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bf3rStwGdSf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2i9DHaS0Gbfq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMe1jhXpGg0j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoi2EUjXGj8c"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qAg3PmFGo5E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CARDt73FGr2T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGZ-9Z2WGuCh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElxFwrtfIie1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NR8Po9IIndJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BT5q0ZLDIpVK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOJ1p8_XIr6Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tyQN2bkIuTa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAAH3IRQIxsK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPyu9-IeIzmX"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4MoCBAXI2Xi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuorVOYOJRLD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KeUSdGCQCCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRVJcGnkQciJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsBmtu4sODh-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0LBVPTTOlYL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1HBcZjqVel5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18375,
     "status": "ok",
     "timestamp": 1763549414323,
     "user": {
      "displayName": "Madhumita Karthikeyan",
      "userId": "12756964649690884911"
     },
     "user_tz": -330
    },
    "id": "7TJzaLSEV6Kd",
    "outputId": "04aaf3ba-0426-49cb-a55e-d05e660ed5c1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "nb_path = '/content/drive/MyDrive/Colab Notebooks/DL_project_new(1).ipynb'\n",
    "print(\"Looking for:\", nb_path)\n",
    "if not os.path.exists(nb_path):\n",
    "    print(\"File not found. Check the path and file name exactly (case-sensitive).\")\n",
    "else:\n",
    "    print(\"File found. Size (bytes):\", os.path.getsize(nb_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBJ1sxOoubDh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNjyiArXrmq5xjdOqz6n1RZ",
   "gpuType": "T4",
   "mount_file_id": "1yy3I1RAckLxvDDuPqz3ZDlkIw0ApCK_g",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
