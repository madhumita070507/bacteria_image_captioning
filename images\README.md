Validation results:
![val_result](https://github.com/user-attachments/assets/6edbff6b-d74a-4eae-b547-8cb767fe8873)

sample:
![sample yolo](https://github.com/user-attachments/assets/682172f5-2a5b-485e-8809-63327a6ed801)

evaluation graphs:
![curves](https://github.com/user-attachments/assets/9bda89bb-2241-4e5a-a89c-4e9966e5f33a)
![curve2](https://github.com/user-attachments/assets/0eccb0d4-943f-47b1-acd7-b579fd13634b)
![curve3](https://github.com/user-attachments/assets/4e2c557a-05c9-4901-ae54-57a4c33234e3)
![curve4](https://github.com/user-attachments/assets/73b5ae8c-99d0-4a5a-ba6f-4dc67a229a2c)

Training results:
![training results](https://github.com/user-attachments/assets/43258b18-94ba-4bd3-a740-4bd3de9a3c52)
![confusionmatix](https://github.com/user-attachments/assets/c6d5a603-addc-438d-8de4-d7d0c7cff4c9)

BLIP and CLIP evaluation
![blip](https://github.com/user-attachments/assets/55b5ed19-1b85-469e-9472-89f550d8ecad)
![clip](https://github.com/user-attachments/assets/435c5675-5d10-494d-b70d-9004775b1acc)

